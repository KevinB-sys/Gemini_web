<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Historia de Gemini - Historia</title>
    <link rel="stylesheet" href="../Estilos/index.css" />
    <link rel="stylesheet" href="../Estilos/historia.css" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <script src="../Scripts/historia.js"></script>
</head>

<body>
    <header class="header-gemini">
        <img src="../Imagenes/gemini-header.jpg" alt="Gemini Header" class="img-header">
    </header>

    <nav class="slide-down">
        <a href="index.html">Inicio</a>
        <a href="historia.html" class="active">Historia</a>
        <a href="funcionalidades.html">Funcionalidades</a>
        <a href="impacto.html">Impacto Académico</a>
        <a href="recursos.html">Recursos y Servicios</a>
    </nav>

    <main class="fade-in-delay">
        <h2>Historia de Gemini</h2>
        <div class="timeline-container">
            <div class="timeline-card" data-year="2022">
                <img src="../Imagenes/gemini-concept-2022.jpg" alt="Concepto Gemini 2022">
                <h3>2022: Primeros Conceptos e Investigación</h3>
                <p>
                    En 2022, los equipos de Google DeepMind comenzaron la fase inicial de investigación y
                    conceptualización
                    para un modelo de IA multimodal de próxima generación. Se exploraron arquitecturas innovadoras y se
                    definieron los objetivos clave de razonamiento avanzado y comprensión multimodal.
                </p>
                <button class="learn-more" data-modal-id="modal-2022">Ver más</button>
            </div>

            <div class="timeline-card" data-year="2023">
                <img src="../Imagenes/gemini-development-2023.png" alt="Desarrollo Gemini 2023">
                <h3>2023: Fase de Desarrollo Intensivo</h3>
                <p>
                    2023 marcó el inicio de la fase de desarrollo intensivo, con la asignación de recursos
                    significativos
                    y la colaboración de múltiples equipos. Se comenzaron a construir los modelos base y se experimentó
                    con grandes conjuntos de datos multimodales.
                </p>
                <button class="learn-more" data-modal-id="modal-2023">Ver más</button>
            </div>

            <div class="timeline-card" data-year="2024">
                <img src="../Imagenes/gemini-integration-2024.jpg" alt="Integración Gemini 2024">
                <h3>2024: Integración y Pruebas Amplias</h3>
                <p>
                    En 2024, Gemini comenzó a integrarse en varios productos y plataformas de Google para pruebas más
                    amplias. Se recopiló retroalimentación valiosa de usuarios internos y externos, lo que permitió
                    refinar
                    el modelo y mejorar su rendimiento en aplicaciones del mundo real.
                </p>
                <button class="learn-more" data-modal-id="modal-2024">Ver más</button>
            </div>

            <div class="timeline-card" data-year="2025">
                <img src="../Imagenes/gemini-launch-2025.jpg" alt="Lanzamiento Gemini 2025">
                <h3>2025: Lanzamiento y Expansión</h3>
                <p>
                    2025 fue el año del lanzamiento oficial de Gemini, marcando un hito en la evolución de la IA
                    multimodal.
                    Desde su lanzamiento, se ha continuado trabajando en la expansión de sus capacidades y su
                    integración
                    en un número creciente de aplicaciones.
                </p>
                <button class="learn-more" data-modal-id="modal-2025">Ver más</button>
            </div>
        </div>
    </main>

    <div class="modal" id="modal-2022">
        <div class="modal-content">
            <h4>2022: Detalles Iniciales</h4>
            <p>
                Durante este año, se sentaron las bases teóricas para la integración de diferentes tipos de
                datos
                (texto, imágenes, audio, código) en un solo modelo. Se realizaron experimentos preliminares con
                diferentes técnicas de aprendizaje automático y se identificaron los desafíos clave a superar.
            </p>
            <button class="close-modal" data-modal-id="modal-2022">Cerrar</button>
        </div>
    </div>

    <div class="modal" id="modal-2023">
        <div class="modal-content">
            <h4>2023: Avances Clave</h4>
            <p>
                Se lograron avances importantes en la arquitectura del modelo, permitiendo una mejor alineación
                entre las diferentes modalidades de entrada. Se desarrollaron técnicas para el entrenamiento
                eficiente de modelos a gran escala y se realizaron pruebas internas para evaluar las capacidades
                iniciales de Gemini.
            </p>
            <button class="close-modal" data-modal-id="modal-2023">Cerrar</button>
        </div>
    </div>

    <div class="modal" id="modal-2024">
        <div class="modal-content">
            <h4>2024: Despliegue Inicial</h4>
            <p>
                Durante este año, se realizaron los primeros despliegues limitados de Gemini en entornos
                controlados.
                Se evaluaron sus capacidades en tareas como el razonamiento sobre imágenes, la comprensión de
                audio
                y la generación de código, obteniendo resultados prometedores.
            </p>
            <button class="close-modal" data-modal-id="modal-2024">Cerrar</button>
        </div>
    </div>

    <div class="modal" id="modal-2025">
        <div class="modal-content">
            <h4>2025: El Presente y el Futuro</h4>
            <p>
                Actualmente, Gemini sigue evolucionando, con actualizaciones periódicas que mejoran su
                rendimiento
                y añaden nuevas funcionalidades. El enfoque se centra en hacerlo más accesible y útil para una
                amplia gama de usuarios y aplicaciones.
            </p>
            <button class="close-modal" data-modal-id="modal-2025">Cerrar</button>
        </div>
    </div>

    <footer class="fade-in-delay">
        © 2025 | Proyecto sobre Gemini IA
    </footer>

    <div class="modal-overlay"></div>

</body>

</html>