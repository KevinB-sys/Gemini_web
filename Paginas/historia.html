<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Historia de Gemini - Historia</title>
    <link rel="stylesheet" href="../Estilos/index.css" />
    <link rel="stylesheet" href="../Estilos/historia.css" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>

<body>
    <header class="header-gemini">
        <img src="../Imagenes/gemini-header.jpg" alt="Gemini Header" class="img-header">
    </header>

    <nav class="slide-down">
        <a href="index.html">Inicio</a>
        <a href="historia.html" class="active">Historia</a>
        <a href="funcionalidades.html">Funcionalidades</a>
        <a href="impacto.html">Impacto Académico</a>
        <a href="recursos.html">Recursos</a>
    </nav>

    <main class="fade-in-delay">
        <h2>Historia de Gemini</h2>
        <div class="timeline-container">
            <div class="timeline-card" data-year="2022">
                <img src="../Imagenes/gemini-concept-2022.jpg" alt="Concepto Gemini 2022">
                <h3>2022: Primeros Conceptos e Investigación</h3>
                <p>
                    En 2022, los equipos de Google DeepMind comenzaron la fase inicial de investigación y conceptualización
                    para un modelo de IA multimodal de próxima generación. Se exploraron arquitecturas innovadoras y se
                    definieron los objetivos clave de razonamiento avanzado y comprensión multimodal.
                </p>
                <button class="learn-more">Ver más</button>
                <div class="info-overlay">
                    <h4>2022: Detalles Iniciales</h4>
                    <p>
                        Durante este año, se sentaron las bases teóricas para la integración de diferentes tipos de datos
                        (texto, imágenes, audio, código) en un solo modelo. Se realizaron experimentos preliminares con
                        diferentes técnicas de aprendizaje automático y se identificaron los desafíos clave a superar.
                    </p>
                    <button class="close-info">Cerrar</button>
                </div>
            </div>

            <div class="timeline-card" data-year="2023">
                <img src="../Imagenes/gemini-development-2023.png" alt="Desarrollo Gemini 2023">
                <h3>2023: Fase de Desarrollo Intensivo</h3>
                <p>
                    2023 marcó el inicio de la fase de desarrollo intensivo, con la asignación de recursos significativos
                    y la colaboración de múltiples equipos. Se comenzaron a construir los modelos base y se experimentó
                    con grandes conjuntos de datos multimodales.
                </p>
                <button class="learn-more">Ver más</button>
                <div class="info-overlay">
                    <h4>2023: Avances Clave</h4>
                    <p>
                        Se lograron avances importantes en la arquitectura del modelo, permitiendo una mejor alineación
                        entre las diferentes modalidades de entrada. Se desarrollaron técnicas para el entrenamiento
                        eficiente de modelos a gran escala y se realizaron pruebas internas para evaluar las capacidades
                        iniciales de Gemini.
                    </p>
                    <button class="close-info">Cerrar</button>
                </div>
            </div>

            <div class="timeline-card" data-year="2024">
                <img src="../Imagenes/gemini-integration-2024.jpg" alt="Integración Gemini 2024">
                <h3>2024: Integración y Pruebas Amplias</h3>
                <p>
                    En 2024, Gemini comenzó a integrarse en varios productos y plataformas de Google para pruebas más
                    amplias. Se recopiló retroalimentación valiosa de usuarios internos y externos, lo que permitió refinar
                    el modelo y mejorar su rendimiento en aplicaciones del mundo real.
                </p>
                <button class="learn-more">Ver más</button>
                <div class="info-overlay">
                    <h4>2024: Despliegue Inicial</h4>
                    <p>
                        Durante este año, se realizaron los primeros despliegues limitados de Gemini en entornos controlados.
                        Se evaluaron sus capacidades en tareas como el razonamiento sobre imágenes, la comprensión de audio
                        y la generación de código, obteniendo resultados prometedores.
                    </p>
                    <button class="close-info">Cerrar</button>
                </div>
            </div>

            <div class="timeline-card" data-year="2025">
                <img src="../Imagenes/gemini-launch-2025.jpg" alt="Lanzamiento Gemini 2025">
                <h3>2025: Lanzamiento y Expansión</h3>
                <p>
                    2025 fue el año del lanzamiento oficial de Gemini, marcando un hito en la evolución de la IA multimodal.
                    Desde su lanzamiento, se ha continuado trabajando en la expansión de sus capacidades y su integración
                    en un número creciente de aplicaciones.
                </p>
                <button class="learn-more">Ver más</button>
                <div class="info-overlay">
                    <h4>2025: El Presente y el Futuro</h4>
                    <p>
                        Actualmente, Gemini sigue evolucionando, con actualizaciones periódicas que mejoran su rendimiento
                        y añaden nuevas funcionalidades. El enfoque se centra en hacerlo más accesible y útil para una
                        amplia gama de usuarios y aplicaciones.
                    </p>
                    <button class="close-info">Cerrar</button>
                </div>
            </div>
        </div>
    </main>

    <footer class="fade-in-delay">
        © 2025 | Proyecto sobre Gemini IA
    </footer>

    <script src="../Animaciones/historia.js"></script>
</body>

</html>